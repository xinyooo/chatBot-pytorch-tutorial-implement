{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "#torch lib\n",
    "import torch\n",
    "#neural network\n",
    "import torch.nn as nn\n",
    "#optimizer ex. momentum,SGD,RMSprop,Adagrad,Adadelta,Adam\n",
    "from torch import optim\n",
    "#loss function ex. softmax *** Activation func?\n",
    "import torch.nn.functional as F\n",
    "#others\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check cuda is available or not\n",
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing datasets\n",
    "#dataset download from http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
    "#datasets file path\n",
    "lines_filepath = os.path.join(\"cornell movie-dialogs corpus\", \"movie_lines.txt\")\n",
    "conv_filepath = os.path.join(\"cornell movie-dialogs corpus\", \"movie_conversations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
      "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n"
     ]
    }
   ],
   "source": [
    "#Visualize some lines\n",
    "with open(lines_filepath, \"r\", encoding=\"iso-8859-1\") as file:\n",
    "    lines = file.readlines()\n",
    "for line in lines[:8]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split each line of the file into a dictionary of fields (lineID, characterID, movieID, character, text)\n",
    "line_fields = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
    "lines = {}\n",
    "with open(lines_filepath, \"r\", encoding=\"iso-8859-1\") as f:\n",
    "    for line in f:\n",
    "        values = line.split(\" +++$+++ \")\n",
    "        #Extract fields\n",
    "        lineObj = {}\n",
    "        if len(values)==5:\n",
    "            for i, field in enumerate(line_fields):\n",
    "                lineObj[field] = values[i]\n",
    "            lines[lineObj[\"lineID\"]] = lineObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('L1045',\n",
       " {'lineID': 'L1045',\n",
       "  'characterID': 'u0',\n",
       "  'movieID': 'm0',\n",
       "  'character': 'BIANCA',\n",
       "  'text': 'They do not!\\n'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lines.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_fields = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
    "conversations = []\n",
    "with open(conv_filepath, \"r\", encoding=\"iso-8859-1\") as f:\n",
    "    for line in f:\n",
    "        values = line.split(\" +++$+++ \")\n",
    "        #Extract fields\n",
    "        convObj = {}\n",
    "        for i, field in enumerate(conv_fields):\n",
    "            convObj[field] = values[i]\n",
    "        #convert string type array data to real array\n",
    "        lineIds = eval(convObj[\"utteranceIDs\"])\n",
    "        #query lines's data then append to convObj[\"lines\"]\n",
    "        convObj[\"lines\"] = []\n",
    "        for lineId in lineIds:\n",
    "            convObj[\"lines\"].append(lines[lineId])\n",
    "        conversations.append(convObj)\n",
    "#Done for extract and combine conversation data to an array..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'character1ID': 'u0',\n",
       " 'character2ID': 'u2',\n",
       " 'movieID': 'm0',\n",
       " 'utteranceIDs': \"['L194', 'L195', 'L196', 'L197']\\n\",\n",
       " 'lines': [{'lineID': 'L194',\n",
       "   'characterID': 'u0',\n",
       "   'movieID': 'm0',\n",
       "   'character': 'BIANCA',\n",
       "   'text': 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\n'},\n",
       "  {'lineID': 'L195',\n",
       "   'characterID': 'u2',\n",
       "   'movieID': 'm0',\n",
       "   'character': 'CAMERON',\n",
       "   'text': \"Well, I thought we'd start with pronunciation, if that's okay with you.\\n\"},\n",
       "  {'lineID': 'L196',\n",
       "   'characterID': 'u0',\n",
       "   'movieID': 'm0',\n",
       "   'character': 'BIANCA',\n",
       "   'text': 'Not the hacking and gagging and spitting part.  Please.\\n'},\n",
       "  {'lineID': 'L197',\n",
       "   'characterID': 'u2',\n",
       "   'movieID': 'm0',\n",
       "   'character': 'CAMERON',\n",
       "   'text': \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\"}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract conversation Q&A\n",
    "qa_pairs = []\n",
    "for conversation in conversations:\n",
    "    #Iterate over all the lines of the conversation\n",
    "    for i in range(len(conversation[\"lines\"]) - 1):\n",
    "        inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "        targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "        #Filter wrong samples (if one of the lists is empty)\n",
    "        if inputLine and targetLine:\n",
    "            qa_pairs.append([inputLine, targetLine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221282"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pairs[:4]\n",
    "len(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing newly formatted file...\n",
      "Done writing to file\n"
     ]
    }
   ],
   "source": [
    "#Save array to a csv file\n",
    "#Define path to new file\n",
    "datafile = os.path.join(\"cornell movie-dialogs corpus\", \"formatted_movie_lines.txt\")\n",
    "delimiter = '\\t'\n",
    "#Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "#Write new csv file\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "with open(datafile, \"w\", encoding=\"utf-8\") as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter)\n",
    "    for pair in qa_pairs:\n",
    "        writer.writerow(pair)\n",
    "print(\"Done writing to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\r\\r\\n\"\n",
      "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\r\\r\\n\"\n",
      "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\r\\r\\n\"\n",
      "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\r\\r\\n\"\n",
      "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\r\\r\\n\"\n",
      "b\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\r\\r\\n\"\n",
      "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\\r\\r\\n\"\n",
      "b'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\r\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "#Visualize some lines\n",
    "datafile = os.path.join(\"cornell movie-dialogs corpus\", \"formatted_movie_lines.txt\")\n",
    "with open(datafile, \"rb\") as file:\n",
    "    lines = file.readlines()\n",
    "for line in lines[:8]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing word\n",
    "PAD_token = 0 #Used for padding short sentences\n",
    "SOS_token = 1 #Start-of-sentence token <START>\n",
    "EOS_token = 2 #End-of-sentence token <END>\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 #Count SOS, EOS, PAD\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    #let the word will not repeat to many times\n",
    "    #Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        keep_words = []\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "        print(\"keep_words {} / {} = {:.4f}\".format(len(keep_words), len(self.word2index), len(keep_words)/len(self.word2index)))\n",
    "        #Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 #Count SOS, EOS, PAD\n",
    "        \n",
    "        for word in keep_words:\n",
    "            self.addWord(word)\n",
    "#End of processing word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing text\n",
    "#Convert unicode to ascii code\n",
    "#NFD=normal form decomposed, Mn=non-marking space\n",
    "def unicodeToAscii(s):\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Montreal,Francoise...'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test **unicodeToAscii** function\n",
    "unicodeToAscii(\"Montreal,Francoise...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lowercase, trim white space, lines...etc., and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    #to lowercase and strip string\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    #replace \"!\" -> \" !\"\n",
    "    s = re.sub(r\"([.!?])\",r\" \\1\", s)\n",
    "    #remove any characters that is not a sequence of lower or upper case letters\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    #remove a sequence of whitespace characters\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa aa !s s dd ?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test **normalizeString** function\n",
    "normalizeString(\"aa123aa!s's     dd?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing file... Please wait\n",
      "Done Reading txt file into array!\n"
     ]
    }
   ],
   "source": [
    "datafile = os.path.join(\"cornell movie-dialogs corpus\", \"formatted_movie_lines.txt\")\n",
    "#Read the file and split into lines\n",
    "print(\"Reading and processing file... Please wait\")\n",
    "lines = open(datafile, encoding=\"utf-8\").read().strip().split('\\n')\n",
    "#Split every line into pairs and normalize\n",
    "pairs = [[normalizeString(s) for s in pair.split('\\t')] for pair in lines]\n",
    "print(\"Done Reading txt file into array!\")\n",
    "voc = Vocabulary(\"cornell movie-dialogs corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return True if both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "MAX_LENGTH = 10 #Maximum sentence length to consider\n",
    "def filterPair(p):\n",
    "    #Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split()) < MAX_LENGTH and len(p[1].split()) < MAX_LENGTH\n",
    "\n",
    "#Filter pairs using **filterPair** condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 221282 pairs/conversations in the dataset\n",
      "After filtering, there are 64271 pairs/converations\n"
     ]
    }
   ],
   "source": [
    "pairs = [pair for pair in pairs if len(pair) > 1]\n",
    "print(\"There are {} pairs/conversations in the dataset\".format(len(pairs)))\n",
    "pairs = filterPairs(pairs)\n",
    "print(\"After filtering, there are {} pairs/converations\".format(len(pairs)))\n",
    "#End for processing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted words:  18008\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "#Getting rid of rare words\n",
    "for pair in pairs:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "print(\"Counted words: \", voc.num_words)\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 7823 / 18005 = 0.4345\n",
      "Trimmed from pairs to 64271, 53165.0000 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3 #\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    #Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    #Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        #Check input sentence\n",
    "        for word in input_sentence.split(\" \"):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        #Check output sentence\n",
    "        for word in output_sentence.split(\" \"):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "        #Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "    print(\"Trimmed from pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs)/len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "#Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)\n",
    "#End for processing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 9, 10, 4, 11, 12, 13, 2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test the function\n",
    "indexesFromSentence(voc, pairs[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you have my word . as a gentleman'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there .', 'you have my word . as a gentleman', 'hi .', 'have fun tonight ?', 'well no . . .', 'then that s all you had to say .', 'but', 'do you listen to this crap ?', 'what good stuff ?', 'wow']\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3, 4, 2],\n",
       " [7, 8, 9, 10, 4, 11, 12, 13, 2],\n",
       " [16, 4, 2],\n",
       " [8, 31, 22, 6, 2],\n",
       " [33, 34, 4, 4, 4, 2],\n",
       " [35, 36, 37, 38, 7, 39, 40, 41, 4, 2],\n",
       " [42, 2],\n",
       " [47, 7, 48, 40, 45, 49, 6, 2],\n",
       " [50, 51, 52, 6, 2],\n",
       " [58, 2]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define some samples for testing\n",
    "inp = []\n",
    "out = []\n",
    "i = 0\n",
    "for pair in pairs[:10]:\n",
    "    inp.append(pair[0])\n",
    "    out.append(pair[1])\n",
    "print(inp)\n",
    "print(len(inp))\n",
    "indexes = [indexesFromSentence(voc, sentence) for sentence in inp]\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroPadding(l, fillvalue = 0):\n",
    "    # * is used for transpose matrix\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leng = [len(ind) for ind in indexes]\n",
    "max(leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 7, 16, 8, 33, 35, 42, 47, 50, 58),\n",
       " (4, 8, 4, 31, 34, 36, 2, 7, 51, 2),\n",
       " (2, 9, 2, 22, 4, 37, 0, 48, 52, 0),\n",
       " (0, 10, 0, 6, 4, 38, 0, 40, 6, 0),\n",
       " (0, 4, 0, 2, 4, 7, 0, 45, 2, 0),\n",
       " (0, 11, 0, 0, 2, 39, 0, 49, 0, 0),\n",
       " (0, 12, 0, 0, 0, 40, 0, 6, 0, 0),\n",
       " (0, 13, 0, 0, 0, 41, 0, 2, 0, 0),\n",
       " (0, 2, 0, 0, 0, 4, 0, 0, 0, 0),\n",
       " (0, 0, 0, 0, 0, 2, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test the function\n",
    "test_result = zeroPadding(indexes)\n",
    "print(len(test_result)) #The max length is now the number of rows\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryMatrix(l, value = 0):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_result = binaryMatrix(test_result)\n",
    "binary_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns padded input sequence tensor and as well as a tensor of lengths for each of the sequence in the batch\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.BoolTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    #Sort the questions in descending length\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    #assert len(inp) == lengths[0]\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "#Done for pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable:\n",
      "tensor([[   7,   25,   25,   65,   50],\n",
      "        [  73,   94,  296,   14,    6],\n",
      "        [ 380, 1262,    7,  187,    2],\n",
      "        [1418,   76,    4,    6,    0],\n",
      "        [   6,    2,    2,    2,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n",
      "lengths:  tensor([6, 5, 5, 5, 3])\n",
      "target_variable:\n",
      "tensor([[  59,    7,  190,  318,   68],\n",
      "        [  83,   94,   51,   65,    7],\n",
      "        [ 158, 1262,   98,   92,  236],\n",
      "        [ 111,   76,   12,    4,   50],\n",
      "        [   4,    6,  180,    2,  101],\n",
      "        [   2,    2, 2730,    0,  215],\n",
      "        [   0,    0, 4780,    0,    6],\n",
      "        [   0,    0,   23,    0,    2],\n",
      "        [   0,    0,    6,    0,    0],\n",
      "        [   0,    0,    2,    0,    0]])\n",
      "mask:\n",
      "tensor([[ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False,  True],\n",
      "        [False, False,  True, False,  True],\n",
      "        [False, False,  True, False,  True],\n",
      "        [False, False,  True, False, False],\n",
      "        [False, False,  True, False, False]])\n",
      "mask_target_len:  10\n"
     ]
    }
   ],
   "source": [
    "#Example fot validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\")\n",
    "print(input_variable)\n",
    "print(\"lengths: \", lengths)\n",
    "print(\"target_variable:\")\n",
    "print(target_variable)\n",
    "print(\"mask:\")\n",
    "print(mask)\n",
    "print(\"mask_target_len: \", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODER\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "    \n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention layer\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "        attn_energies = attn_energies.t()\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECODER\n",
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        #Defne layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers ==1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "        \n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        output = self.out(concat_output)\n",
    "        outout = F.softmax(output, dim=1)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(decoder_out, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    target = target.view(-1, 1)\n",
    "    gathered_tensor = torch.gather(decoder_out, 1, target)\n",
    "    crossEntropy = -torch.log(gathered_tensor)\n",
    "    loss = crossEntropy.masked_select(mask)\n",
    "    loss = loss.mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable shape:  torch.Size([6, 5])\n",
      "lengths shape:  torch.Size([5])\n",
      "target_variable shape:  torch.Size([10, 5])\n",
      "mask shape:  torch.Size([10, 5])\n",
      "max_target_len:  10\n",
      "Encoder Outputs Shape:  torch.Size([6, 5, 500])\n",
      "Last Encoder Hidden Shape:  torch.Size([4, 5, 500])\n",
      "Initial Decoder Input Shape:  torch.Size([1, 5])\n",
      "tensor([[1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Initial Decoder hidden statr shape:  torch.Size([2, 5, 500])\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Now Let's look what's happening in every timestep of the GRU!\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape:  torch.Size([5, 7826])\n",
      "Decoder Hidden Shape:  torch.Size([2, 5, 500])\n",
      "The target variable at the current timestep before reshaping:  tensor([ 59,   7, 190, 318,  68], device='cuda:0')\n",
      "The target variable at the current timestep shape before reshaping:  torch.Size([5])\n",
      "The Decoder input shape (reshape the target variable):  torch.Size([1, 5])\n",
      "The mask at the current timestep:  tensor([True, True, True, True, True], device='cuda:0')\n",
      "The mask at the curremt timestep shape:  torch.Size([5])\n",
      "Mask Loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total:  5\n",
      "mask_loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "[nan]\n",
      "Returned Loss:  nan\n",
      "\n",
      "\n",
      "--------------------DONE ONE TIMESTEP--------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape:  torch.Size([5, 7826])\n",
      "Decoder Hidden Shape:  torch.Size([2, 5, 500])\n",
      "The target variable at the current timestep before reshaping:  tensor([83, 94, 51, 65,  7], device='cuda:0')\n",
      "The target variable at the current timestep shape before reshaping:  torch.Size([5])\n",
      "The Decoder input shape (reshape the target variable):  torch.Size([1, 5])\n",
      "The mask at the current timestep:  tensor([True, True, True, True, True], device='cuda:0')\n",
      "The mask at the curremt timestep shape:  torch.Size([5])\n",
      "Mask Loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total:  5\n",
      "mask_loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "[nan, nan]\n",
      "Returned Loss:  nan\n",
      "\n",
      "\n",
      "--------------------DONE ONE TIMESTEP--------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape:  torch.Size([5, 7826])\n",
      "Decoder Hidden Shape:  torch.Size([2, 5, 500])\n",
      "The target variable at the current timestep before reshaping:  tensor([ 158, 1262,   98,   92,  236], device='cuda:0')\n",
      "The target variable at the current timestep shape before reshaping:  torch.Size([5])\n",
      "The Decoder input shape (reshape the target variable):  torch.Size([1, 5])\n",
      "The mask at the current timestep:  tensor([True, True, True, True, True], device='cuda:0')\n",
      "The mask at the curremt timestep shape:  torch.Size([5])\n",
      "Mask Loss:  tensor(4.1485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total:  5\n",
      "mask_loss:  tensor(4.1485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "[nan, nan, 20.742666721343994]\n",
      "Returned Loss:  nan\n",
      "\n",
      "\n",
      "--------------------DONE ONE TIMESTEP--------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape:  torch.Size([5, 7826])\n",
      "Decoder Hidden Shape:  torch.Size([2, 5, 500])\n",
      "The target variable at the current timestep before reshaping:  tensor([111,  76,  12,   4,  50], device='cuda:0')\n",
      "The target variable at the current timestep shape before reshaping:  torch.Size([5])\n",
      "The Decoder input shape (reshape the target variable):  torch.Size([1, 5])\n",
      "The mask at the current timestep:  tensor([True, True, True, True, True], device='cuda:0')\n",
      "The mask at the curremt timestep shape:  torch.Size([5])\n",
      "Mask Loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total:  5\n",
      "mask_loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "[nan, nan, 20.742666721343994, nan]\n",
      "Returned Loss:  nan\n",
      "\n",
      "\n",
      "--------------------DONE ONE TIMESTEP--------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape:  torch.Size([5, 7826])\n",
      "Decoder Hidden Shape:  torch.Size([2, 5, 500])\n",
      "The target variable at the current timestep before reshaping:  tensor([  4,   6, 180,   2, 101], device='cuda:0')\n",
      "The target variable at the current timestep shape before reshaping:  torch.Size([5])\n",
      "The Decoder input shape (reshape the target variable):  torch.Size([1, 5])\n",
      "The mask at the current timestep:  tensor([True, True, True, True, True], device='cuda:0')\n",
      "The mask at the curremt timestep shape:  torch.Size([5])\n",
      "Mask Loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total:  5\n",
      "mask_loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "[nan, nan, 20.742666721343994, nan, nan]\n",
      "Returned Loss:  nan\n",
      "\n",
      "\n",
      "--------------------DONE ONE TIMESTEP--------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape:  torch.Size([5, 7826])\n",
      "Decoder Hidden Shape:  torch.Size([2, 5, 500])\n",
      "The target variable at the current timestep before reshaping:  tensor([   2,    2, 2730,    0,  215], device='cuda:0')\n",
      "The target variable at the current timestep shape before reshaping:  torch.Size([5])\n",
      "The Decoder input shape (reshape the target variable):  torch.Size([1, 5])\n",
      "The mask at the current timestep:  tensor([ True,  True,  True, False,  True], device='cuda:0')\n",
      "The mask at the curremt timestep shape:  torch.Size([5])\n",
      "Mask Loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total:  4\n",
      "mask_loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "[nan, nan, 20.742666721343994, nan, nan, nan]\n",
      "Returned Loss:  nan\n",
      "\n",
      "\n",
      "--------------------DONE ONE TIMESTEP--------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape:  torch.Size([5, 7826])\n",
      "Decoder Hidden Shape:  torch.Size([2, 5, 500])\n",
      "The target variable at the current timestep before reshaping:  tensor([   0,    0, 4780,    0,    6], device='cuda:0')\n",
      "The target variable at the current timestep shape before reshaping:  torch.Size([5])\n",
      "The Decoder input shape (reshape the target variable):  torch.Size([1, 5])\n",
      "The mask at the current timestep:  tensor([False, False,  True, False,  True], device='cuda:0')\n",
      "The mask at the curremt timestep shape:  torch.Size([5])\n",
      "Mask Loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total:  2\n",
      "mask_loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "[nan, nan, 20.742666721343994, nan, nan, nan, nan]\n",
      "Returned Loss:  nan\n",
      "\n",
      "\n",
      "--------------------DONE ONE TIMESTEP--------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape:  torch.Size([5, 7826])\n",
      "Decoder Hidden Shape:  torch.Size([2, 5, 500])\n",
      "The target variable at the current timestep before reshaping:  tensor([ 0,  0, 23,  0,  2], device='cuda:0')\n",
      "The target variable at the current timestep shape before reshaping:  torch.Size([5])\n",
      "The Decoder input shape (reshape the target variable):  torch.Size([1, 5])\n",
      "The mask at the current timestep:  tensor([False, False,  True, False,  True], device='cuda:0')\n",
      "The mask at the curremt timestep shape:  torch.Size([5])\n",
      "Mask Loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total:  2\n",
      "mask_loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "[nan, nan, 20.742666721343994, nan, nan, nan, nan, nan]\n",
      "Returned Loss:  nan\n",
      "\n",
      "\n",
      "--------------------DONE ONE TIMESTEP--------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape:  torch.Size([5, 7826])\n",
      "Decoder Hidden Shape:  torch.Size([2, 5, 500])\n",
      "The target variable at the current timestep before reshaping:  tensor([0, 0, 6, 0, 0], device='cuda:0')\n",
      "The target variable at the current timestep shape before reshaping:  torch.Size([5])\n",
      "The Decoder input shape (reshape the target variable):  torch.Size([1, 5])\n",
      "The mask at the current timestep:  tensor([False, False,  True, False, False], device='cuda:0')\n",
      "The mask at the curremt timestep shape:  torch.Size([5])\n",
      "Mask Loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total:  1\n",
      "mask_loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "[nan, nan, 20.742666721343994, nan, nan, nan, nan, nan, nan]\n",
      "Returned Loss:  nan\n",
      "\n",
      "\n",
      "--------------------DONE ONE TIMESTEP--------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape:  torch.Size([5, 7826])\n",
      "Decoder Hidden Shape:  torch.Size([2, 5, 500])\n",
      "The target variable at the current timestep before reshaping:  tensor([0, 0, 2, 0, 0], device='cuda:0')\n",
      "The target variable at the current timestep shape before reshaping:  torch.Size([5])\n",
      "The Decoder input shape (reshape the target variable):  torch.Size([1, 5])\n",
      "The mask at the current timestep:  tensor([False, False,  True, False, False], device='cuda:0')\n",
      "The mask at the curremt timestep shape:  torch.Size([5])\n",
      "Mask Loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total:  1\n",
      "mask_loss:  tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "[nan, nan, 20.742666721343994, nan, nan, nan, nan, nan, nan, nan]\n",
      "Returned Loss:  nan\n",
      "\n",
      "\n",
      "--------------------DONE ONE TIMESTEP--------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "small_batch_size = 5\n",
    "batched = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, length, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable shape: \", input_variable.shape)\n",
    "print(\"lengths shape: \", lengths.shape)\n",
    "print(\"target_variable shape: \", target_variable.shape)\n",
    "print(\"mask shape: \", mask.shape)\n",
    "print(\"max_target_len: \", max_target_len)\n",
    "\n",
    "#Define the parameters\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "attn_model = 'dot'\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "\n",
    "##Define the encoder and decoder\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "#Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "#Initialize optimizers\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.0001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.0001)\n",
    "encoder_optimizer.zero_grad()\n",
    "decoder_optimizer.zero_grad()\n",
    "\n",
    "input_variable = input_variable.to(device)\n",
    "lengths = lengths.to(device)\n",
    "target_variable = target_variable.to(device)\n",
    "mask = mask.to(device)\n",
    "\n",
    "loss = 0\n",
    "print_losses = []\n",
    "n_totals = 0\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "print(\"Encoder Outputs Shape: \", encoder_outputs.shape)\n",
    "print(\"Last Encoder Hidden Shape: \", encoder_hidden.shape)\n",
    "\n",
    "decoder_input = torch.LongTensor([[SOS_token for _ in range(small_batch_size)]])\n",
    "decoder_input = decoder_input.to(device)\n",
    "print(\"Initial Decoder Input Shape: \", decoder_input.shape)\n",
    "print(decoder_input)\n",
    "\n",
    "#Set initial decoder hidden state to the encoder's final hidden state\n",
    "decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "print(\"Initial Decoder hidden statr shape: \", decoder_hidden.shape)\n",
    "print(\"\\n\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Now Let's look what's happening in every timestep of the GRU!\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#Assume we are using Teacher Forcing\n",
    "for t in range(max_target_len):\n",
    "    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    print(\"Decoder Output Shape: \", decoder_output.shape)\n",
    "    print(\"Decoder Hidden Shape: \", decoder_hidden.shape)\n",
    "    #Teacher forcing: next input is current target\n",
    "    decoder_input = target_variable[t].view(1, -1)\n",
    "    print(\"The target variable at the current timestep before reshaping: \", target_variable[t])\n",
    "    print(\"The target variable at the current timestep shape before reshaping: \", target_variable[t].shape)\n",
    "    print(\"The Decoder input shape (reshape the target variable): \", decoder_input.shape)\n",
    "    #Calculate and accumulate loss\n",
    "    print(\"The mask at the current timestep: \", mask[t])\n",
    "    print(\"The mask at the curremt timestep shape: \", mask[t].shape)\n",
    "    mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "    print(\"Mask Loss: \", mask_loss)\n",
    "    print(\"Total: \", nTotal)\n",
    "    loss += mask_loss\n",
    "    print_losses.append(mask_loss.item() * nTotal)\n",
    "    print(print_losses)\n",
    "    n_totals += nTotal\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    returned_loss = sum(print_losses) / n_totals\n",
    "    print(\"Returned Loss: \", returned_loss)\n",
    "    print(\"\\n\")\n",
    "    print(\"--------------------DONE ONE TIMESTEP--------------------\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
